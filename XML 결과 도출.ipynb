{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"D1JUzKop0VWV","executionInfo":{"status":"ok","timestamp":1718384366509,"user_tz":-540,"elapsed":2987,"user":{"displayName":"이연우","userId":"11699360281048341649"}}},"outputs":[],"source":["import os\n","from bs4 import BeautifulSoup\n","import csv\n","import networkx as nx\n","import matplotlib.pyplot as plt\n","import plotly.graph_objects as go\n","import plotly.io as pio\n","import plotly.express as px\n","import pandas as pd"]},{"cell_type":"code","source":["# Mount Google Drive (optional, if you're using Google Drive)\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"29C6viLI4XxO","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b572ef06-267d-4d0f-adab-d63f5a8eadb8","executionInfo":{"status":"ok","timestamp":1718384394889,"user_tz":-540,"elapsed":28386,"user":{"displayName":"이연우","userId":"11699360281048341649"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["data_dir = '/content/input/'\n","output_dir = '/content/output'\n","\n","if not os.path.exists(output_dir):\n","    os.makedirs(output_dir)"],"metadata":{"id":"c5SJZuyw4bA8","executionInfo":{"status":"ok","timestamp":1718384394889,"user_tz":-540,"elapsed":5,"user":{"displayName":"이연우","userId":"11699360281048341649"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def read_xml_and_create_matrix(file_path):\n","    # Read the XML file\n","    with open(file_path, 'r', encoding='utf-8') as file:\n","        contents = file.read()\n","\n","    # Parse the XML with BeautifulSoup\n","    soup = BeautifulSoup(contents, 'xml')\n","\n","    # Dictionary to store the count of interactions\n","    interactions = {}\n","\n","    # Iterate over the dialogue elements\n","    for dialogue in soup.find_all('dialogue'):\n","        speaker = dialogue.find('speaker').text if dialogue.find('speaker') else None\n","        receiver = dialogue.find('receiver').text if dialogue.find('receiver') else None\n","\n","        if not speaker or not receiver:\n","            continue\n","\n","        # Check and initialize if speaker or receiver is not in dictionary\n","        if speaker not in interactions:\n","            interactions[speaker] = {}\n","        if receiver not in interactions[speaker]:\n","            interactions[speaker][receiver] = 0\n","\n","        # Increment the count of interaction\n","        interactions[speaker][receiver] += 1\n","\n","    # Generate a list of unique speakers\n","    speakers = list(set([dialogue.find('speaker').text for dialogue in soup.find_all('dialogue') if dialogue.find('speaker')]))\n","\n","    # Convert the dictionary into a matrix\n","    matrix = []\n","    for speaker in speakers:\n","        row = [interactions.get(speaker, {}).get(recv, 0) for recv in speakers]\n","        matrix.append(row)\n","\n","    return speakers, matrix\n","\n","def save_matrix_to_csv(speakers, matrix, output_file, suffix=\"_matrix\"):\n","    # Create the output file name by appending the suffix and .csv extension\n","    output_file = f\"{output_file}{suffix}.csv\"\n","\n","    with open(output_file, 'w', newline='') as csvfile:\n","        writer = csv.writer(csvfile)\n","        writer.writerow(['Speaker/Receiver'] + speakers)  # Header row\n","        for i, row in enumerate(matrix):\n","            writer.writerow([speakers[i]] + row)\n","\n","def create_network_from_matrix(speakers, matrix):\n","    G = nx.Graph()\n","\n","    # Iterate over the matrix to add edges\n","    for i, speaker in enumerate(speakers):\n","        for j, count in enumerate(matrix[i]):\n","            receiver = speakers[j]\n","            if count > 0 and speaker != receiver:  # Check to avoid self-loops\n","                G.add_edge(speaker, receiver, weight=count)\n","\n","    return G\n","\n","def visualize_network_interactive(G, output_file, suffix=\"_network\"):\n","    pos = nx.spring_layout(G)\n","\n","    edge_x = []\n","    edge_y = []\n","    for edge in G.edges():\n","        x0, y0 = pos[edge[0]]\n","        x1, y1 = pos[edge[1]]\n","        edge_x.extend([x0, x1, None])\n","        edge_y.extend([y0, y1, None])\n","\n","    edge_trace = go.Scatter(x=edge_x, y=edge_y,\n","                            line=dict(width=0.5, color='#888'),\n","                            hoverinfo='none',\n","                            mode='lines')\n","\n","    node_x = []\n","    node_y = []\n","    for node in G.nodes():\n","        x, y = pos[node]\n","        node_x.append(x)\n","        node_y.append(y)\n","\n","    node_trace = go.Scatter(x=node_x, y=node_y,\n","                            mode='markers+text',\n","                            text=[node for node in G.nodes()],\n","                            textposition=\"top center\",\n","                            hoverinfo='text',\n","                            marker=dict(showscale=True,\n","                                        colorscale='HOT',\n","                                        reversescale=True,\n","                                        color=[],\n","                                        size=10,\n","                                        colorbar=dict(thickness=15,\n","                                                      title='Number of Interactions',\n","                                                      xanchor='left',\n","                                                      titleside='right')))\n","\n","    node_adjacencies = []\n","    for node, adjacencies in enumerate(G.adjacency()):\n","        node_adjacencies.append(len(adjacencies[1]))\n","\n","    node_trace.marker.color = node_adjacencies\n","\n","    fig = go.Figure(data=[edge_trace, node_trace],\n","                    layout=go.Layout(showlegend=False,\n","                                      hovermode='closest',\n","                                      margin=dict(b=20, l=5, r=5, t=40),\n","                                      xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n","                                      yaxis=dict(showgrid=False, zeroline=False, showticklabels=False)))\n","\n","    output_file = f\"{output_file}{suffix}.html\"\n","\n","    # Save to HTML\n","    pio.write_html(fig, file=output_file)\n","\n","def count_words_in_line(line):\n","    return len(line.split())\n","\n","def read_xml_and_create_word_count_matrix(file_path):\n","    # Read the XML file\n","    with open(file_path, 'r', encoding='utf-8') as file:\n","        contents = file.read()\n","\n","    # Parse the XML with BeautifulSoup\n","    soup = BeautifulSoup(contents, 'xml')\n","\n","    # Dictionary to store the word count of interactions\n","    word_count_interactions = {}\n","\n","    # Iterate over the dialogue elements\n","    for dialogue in soup.find_all('dialogue'):\n","        speaker = dialogue.find('speaker').text if dialogue.find('speaker') else None\n","        receiver = dialogue.find('receiver').text if dialogue.find('receiver') else None\n","        line = dialogue.find('line').text if dialogue.find('line') else \"\"\n","\n","        if not speaker or not receiver:\n","            continue\n","\n","        # Initialize dictionary entries if not present\n","        if speaker not in word_count_interactions:\n","            word_count_interactions[speaker] = {}\n","        if receiver not in word_count_interactions[speaker]:\n","            word_count_interactions[speaker][receiver] = 0\n","\n","        # Count the words and add to the corresponding speaker-receiver pair\n","        word_count_interactions[speaker][receiver] += count_words_in_line(line)\n","\n","    # Generate a list of unique speakers\n","    speakers = list(set([dialogue.find('speaker').text for dialogue in soup.find_all('dialogue') if dialogue.find('speaker')]))\n","\n","    # Convert the dictionary into a matrix\n","    matrix = []\n","    for speaker in speakers:\n","        row = [word_count_interactions.get(speaker, {}).get(recv, 0) for recv in speakers]\n","        matrix.append(row)\n","\n","    return speakers, matrix\n","\n","def girvan_newman_community_detection(G):\n","    communities_generator = nx.community.girvan_newman(G)\n","    top_level_communities = next(communities_generator)\n","    partition = {node: cid for cid, community in enumerate(top_level_communities) for node in community}\n","    return partition\n","\n","def visualize_communities(G, partition, output_file, suffix=\"_communities\"):\n","    # Position the nodes using the spring layout algorithm\n","    pos = nx.spring_layout(G)\n","\n","    # Create empty lists to store the node and edge data\n","    edge_x = []\n","    edge_y = []\n","    node_x = []\n","    node_y = []\n","    node_color = []\n","\n","    # Iterate over the edges to prepare edge traces\n","    for edge in G.edges():\n","        x0, y0 = pos[edge[0]]\n","        x1, y1 = pos[edge[1]]\n","        edge_x.extend([x0, x1, None])\n","        edge_y.extend([y0, y1, None])\n","\n","    # Create an edge trace\n","    edge_trace = go.Scatter(\n","        x=edge_x, y=edge_y,\n","        line=dict(width=0.5, color='#888'),\n","        hoverinfo='none',\n","        mode='lines')\n","\n","    # Iterate over the nodes to prepare node traces\n","    for node in G.nodes():\n","        x, y = pos[node]\n","        node_x.append(x)\n","        node_y.append(y)\n","        node_color.append(partition[node])\n","\n","    # Create a node trace\n","    node_trace = go.Scatter(\n","        x=node_x, y=node_y,\n","        mode='markers+text',\n","        text=[node for node in G.nodes()],\n","        textposition=\"top center\",\n","        hoverinfo='text',\n","        marker=dict(\n","            showscale=True,\n","            colorscale='Viridis',\n","            color=node_color,\n","            size=10,\n","            line_width=2))\n","\n","    # Add node labels\n","    node_trace.text = [str(node) for node in G.nodes()]\n","\n","    # Create a figure\n","    fig = go.Figure(data=[edge_trace, node_trace],\n","                    layout=go.Layout(\n","                        title='<br>Network graph with communities',\n","                        titlefont_size=16,\n","                        showlegend=False,\n","                        hovermode='closest',\n","                        margin=dict(b=20,l=5,r=5,t=40),\n","                        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n","                        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False))\n","                    )\n","\n","    output_file = f\"{output_file}{suffix}.html\"\n","    fig.write_html(output_file)  # Save as HTML\n","\n","def calculate_plot_save_centrality(G, output_file, suffix=\"\"):\n","    # Calculate centrality scores\n","    centrality_scores = {\n","        'Degree Centrality': nx.degree_centrality(G),\n","        'Betweenness Centrality': nx.betweenness_centrality(G),\n","        'Closeness Centrality': nx.closeness_centrality(G),\n","        'Eigenvector Centrality': nx.eigenvector_centrality(G, max_iter=1000)\n","    }\n","\n","    # Convert centrality scores to DataFrame for plotting and saving\n","    df = pd.DataFrame(centrality_scores)\n","    df.index.name = 'Node'\n","    df.reset_index(inplace=True)\n","    df_melted = df.melt(id_vars=['Node'], var_name='Centrality Type', value_name='Score')\n","\n","    # Plot the centrality scores\n","    fig = px.bar(df_melted, x='Node', y='Score', color='Centrality Type', barmode='group')\n","    fig.update_layout(title_text='Centrality Scores of Nodes in the Network')\n","    plot_file = f\"{output_file}{suffix}_centrality_plot.html\"\n","    fig.write_html(plot_file)\n","\n","    # Save the centrality scores to a CSV file\n","    csv_file = f\"{output_file}{suffix}_centrality_scores.csv\"\n","    df.to_csv(csv_file, index=False)\n"],"metadata":{"id":"kKpsnYAWue5h","executionInfo":{"status":"ok","timestamp":1718384458491,"user_tz":-540,"elapsed":503,"user":{"displayName":"이연우","userId":"11699360281048341649"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["for file_name in [f for f in os.listdir(data_dir) if f.endswith('.xml')]:\n","    print(f\"Processing {file_name}\")\n","    speakers, matrix = read_xml_and_create_matrix(os.path.join(data_dir, file_name))\n","    output_file = os.path.join(output_dir, file_name.split('.')[0])\n","    save_matrix_to_csv(speakers, matrix, output_file)\n","    G = create_network_from_matrix(speakers, matrix)\n","    visualize_network_interactive(G, output_file)\n","\n","    speakers_words, matrix_words = read_xml_and_create_word_count_matrix(os.path.join(data_dir, file_name))\n","    save_matrix_to_csv(speakers_words, matrix_words, output_file, \"_words_matrix\")\n","    G_words = create_network_from_matrix(speakers_words, matrix_words)\n","    visualize_network_interactive(G_words, output_file, \"_words_network\")\n","\n","    partition = girvan_newman_community_detection(G)\n","    partition_words = girvan_newman_community_detection(G_words)\n","    visualize_communities(G, partition, output_file)\n","    visualize_communities(G_words, partition_words, output_file, \"_words_communities\")\n","\n","    calculate_plot_save_centrality(G, output_file)\n","    calculate_plot_save_centrality(G_words, output_file, \"_words_combined_centrality_scores\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ognoGvFjukke","outputId":"785ed965-8697-4c36-badb-026483ae028e","executionInfo":{"status":"ok","timestamp":1718386134374,"user_tz":-540,"elapsed":5444,"user":{"displayName":"이연우","userId":"11699360281048341649"}}},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing Age_of_Ultron_xml.xml\n","Processing Infinity_War_xml.xml\n"]}]}]}